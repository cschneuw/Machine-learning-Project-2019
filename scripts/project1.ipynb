{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Presentation and Pre-Processing\n",
    "Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "#import os\n",
    "#data_base_path = os.path.join(os.pardir, 'data')\n",
    "#data_folder = 'train.csv'\n",
    "#data_path = os.path.join(data_base_path, data_folder)\n",
    "#y, tX, ids = load_csv_data(data_path)\n",
    "\n",
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple data description (change later)\n",
    "- all variables are floating point, except PRI_jet_num which is integer\n",
    "- variables prefixed with PRI (for PRImitives) are “raw” quantities about the bunch collision as measured by the detector.\n",
    "- variables prefixed with DER (for DERived) are quantities computed from the primitive features, which were selected by the physicists of ATLAS.\n",
    "- it can happen that for some entries some variables are meaningless or cannot be computed; in this case, their value is −999.0, which is outside the normal range of all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape = (250000,)\n",
      "tX shape =(250000, 30)\n",
      "ids shape = (250000,)\n"
     ]
    }
   ],
   "source": [
    "print('y shape = ' + str(y.shape) + '\\ntX shape =' + str(tX.shape) + '\\nids shape = ' + str(ids.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the data:\n",
    "- `y` (N) is composed of the labels (-1 or 1) of all the samples.  \n",
    "- `tX` (N x F) is composed of the values of the features (F) for all samples (N)  \n",
    "- `ids` (N) is composed of all the index (100000-349999) of the samples (N)  \n",
    "  \n",
    "Moreover, the number of features is 30 (F=30) and the number of samples is 250'000 (N=250'000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire d'après Robin: Dataprocessing: \n",
    "- Truc qui évalue les NA\n",
    "- Fonction qui vire ou non un featues basé sur un seul\n",
    "- Remplace les NA par la moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations_master import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing the meaningless values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting the meaningless values to \"nan\"\n",
    "tX0 = np.where(tX==-999, np.nan,tX) #nanmin nanstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONNAL: replaces the nan values by medians\n",
    "med_X = np.nanmedian(tX, axis=0)\n",
    "inds = np.where(np.isnan(tX))\n",
    "tX[inds] = np.take(med_X, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONNAL : keep only columns that do not have too much missing data\n",
    "tX, rmX = train_data_formatting(tX, degree = 1, cutoff = 0.7, \n",
    "                      imputation = impute_median, interaction = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers based on the plots in the Exploratory analysis\n",
    "y, tX = remove_outliers(y, tX, [0, 2, 3, 8, 13, 16, 19, 21, 23, 26],\n",
    "                       [1100, 1000, 1000, 2500, 500, 500, 800, 1800, 800, 600])\n",
    "idx0, y_jet0, tX_jet0, idx1, y_jet1, tX_jet1, idx2, y_jet2, tX_jet2 = separate_jet(y, tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONNAL: remove categorical data\n",
    "tX = np.delete(tX, 22, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmX = np.append(rmX, 22)\n",
    "tX = np.apply_along_axis(standardize, 1, tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_jet0 = np.delete(tX_jet0, 22, axis=1)\n",
    "tX_jet1 = np.delete(tX_jet1, 22, axis=1)\n",
    "tX_jet2 = np.delete(tX_jet2, 22, axis=1)\n",
    "tX_jet0, rmX_jet0 = train_data_formatting(tX_jet0, degree = 1, cutoff = 0.95, \n",
    "                      imputation = impute_median, interaction = False)\n",
    "tX_jet1, rmX_jet1 = train_data_formatting(tX_jet1, degree = 1, cutoff = 0.95, \n",
    "                      imputation = impute_median, interaction = False)\n",
    "tX_jet2, rmX_jet2 = train_data_formatting(tX_jet2, degree = 1, cutoff = 0.95, \n",
    "                      imputation = impute_median, interaction = False)\n",
    "rmX_jet0 = np.append(rmX_jet0, 22)\n",
    "rmX_jet1 = np.append(rmX_jet1, 22)\n",
    "rmX_jet2 = np.append(rmX_jet2, 22)\n",
    "tX_jet0 = np.apply_along_axis(standardize, 1, tX_jet0)\n",
    "tX_jet1 = np.apply_along_axis(standardize, 1, tX_jet1)\n",
    "tX_jet2 = np.apply_along_axis(standardize, 1, tX_jet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tX shape={tXs}\\ntX_jet0 shape={tX0s}\\ntX_jet1 shape={tX1s}\\ntX_jet2+ shape={tX2s}\".format(\n",
    "    tXs=tX.shape, tX0s=tX_jet0.shape, tX1s=tX_jet1.shape, tX2s=tX_jet2.shape))\n",
    "\n",
    "print(\"\\nremoved columns for :\\ntX={rmX}\\ntX_jet0={rmX0}\\ntX_jet1={rmX1}\\ntX_jet2+={rmX2}\".format(\n",
    "    rmX=rmX, rmX0=rmX_jet0, rmX1=rmX_jet1, rmX2=rmX_jet2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a sub-sample of training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "tX = tX[:n]\n",
    "y = y[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for f in [2, 6, 10, 15, 20, 27]:\n",
    "    plot_feature(ids, tX0, y, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Least squares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w_ls, loss_ls) = least_squares(y, ntX)\n",
    "\n",
    "print(\"w* ={w}\\n\\nmse={loss}\".format(\n",
    "    w=w_ls, loss=loss_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Least squares with Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters\n",
    "\n",
    "initial_w = np.zeros(ntX.shape[1])\n",
    "max_iters = 100\n",
    "gammas = np.logspace(-6, -1, 50)\n",
    "\n",
    "losses_gd = []\n",
    "ws_gd = []\n",
    "for gamma in gammas:\n",
    "    (w, loss) = least_squares_GD(y, ntX, initial_w, max_iters, gamma)\n",
    "    losses_gd.append(loss)\n",
    "    ws_gd.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the losses per gamma\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(gammas, losses_gd)\n",
    "\n",
    "ax.set(xlabel='gamma', ylabel='MSE',\n",
    "       title='Mean square error per choice of learning rate')\n",
    "ax.grid()\n",
    "ax.set_ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmin(losses_gd)\n",
    "\n",
    "loss_gd = losses_gd[idx]\n",
    "w_gd = ws_gd[idx]\n",
    "gamma_gd = gammas[idx]\n",
    "\n",
    "print(\"w* ={w}\\n\\nmse={loss}\\n\\ngamma={gamma}\".format(\n",
    "    w=w_gd, loss=loss_gd, gamma=gamma_gd ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Least squares with Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(ntX.shape[1])\n",
    "max_iters = 100\n",
    "gammas = np.logspace(-6, -1, 50)\n",
    "\n",
    "losses_sgd = [None] * len(gammas)\n",
    "ws_sgd = [None] * len(gammas)\n",
    "for g in range(len(gammas)):\n",
    "    (ws_sgd[g], losses_sgd[g]) = least_squares_SGD(y, ntX, initial_w, max_iters, gammas[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the losses per gamma used\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(gammas, losses_sgd)\n",
    "\n",
    "ax.set(xlabel='gamma', ylabel='MSE',\n",
    "       title='Mean square error per choice of learning rate')\n",
    "ax.grid()\n",
    "ax.set_ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmin(losses_sgd)\n",
    "\n",
    "loss_sgd = losses_sgd[idx]\n",
    "w_sgd = ws_sgd[idx]\n",
    "gamma_sgd = gammas[idx]\n",
    "\n",
    "print(\"w* ={w}\\n\\nmse={loss}\\n\\ngamma={gamma}\".format(\n",
    "    w=ws_sgd[-1], loss=loss_sgd, gamma = gamma_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cross-validation hyperparameter selection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "degree = 2\n",
    "k_fold = 4\n",
    "lambdas = np.logspace(-15, -1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = y[0:20000]\n",
    "mtX = ntX[0:20000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_indices = build_k_indices(my, k_fold, seed)\n",
    "\n",
    "rmse_tr_cv = []\n",
    "rmse_te_cv = []\n",
    "\n",
    "for lambda_ in  lambdas:\n",
    "    l_rmse_tr = []\n",
    "    l_rmse_te = []\n",
    "    for k in range(k_fold):\n",
    "        loss_tr, loss_te = cross_validation(my, mtX, k_indices, k, lambda_, degree)\n",
    "        l_rmse_tr.append(np.sqrt(2*loss_tr))\n",
    "        l_rmse_te.append(np.sqrt(2*loss_te))\n",
    "    rmse_tr_cv.append(np.mean(l_rmse_tr))\n",
    "    rmse_te_cv.append(np.mean(l_rmse_te))\n",
    "cross_validation_visualization(lambdas, rmse_tr_cv, rmse_te_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmin(rmse_te_cv)\n",
    "lambda_ri = lambdas[idx]\n",
    "\n",
    "print(\"lambda* ={lambda_}\\n\\nrmse train={rmse_tr}\\n\\nrmse test={rmse_te}\".format(\n",
    "    lambda_=lambda_ri, rmse_tr=rmse_tr_cv[idx], rmse_te=rmse_te_cv[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bias-variance decomposition for complexity determination*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = range(10)\n",
    "ratio_train = 0.7\n",
    "degrees = range(1, 12)\n",
    "\n",
    "rmse_tr_bv = np.empty((len(seeds), len(degrees)))\n",
    "rmse_te_bv = np.empty((len(seeds), len(degrees)))\n",
    "\n",
    "for index_seed, seed in enumerate(seeds):\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    x_tr, x_te, y_tr, y_te = split_data(mtX, my, ratio_train, seed)        \n",
    "        \n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    \n",
    "    for index_deg, deg in enumerate(degrees): \n",
    "        tx_tr = build_poly(x_tr, deg)\n",
    "        tx_te = build_poly(x_te, deg)\n",
    "            \n",
    "        w_tr, mse_tr = least_squares(y_tr, tx_tr)\n",
    "        mse_te = compute_mse(y_te, tx_te, w_tr)\n",
    "            \n",
    "        rmse_tr_bv[index_seed][index_deg] = np.sqrt(2*np.array(mse_tr))\n",
    "        rmse_te_bv[index_seed][index_deg] = np.sqrt(2*np.array(mse_te))\n",
    "\n",
    "bias_variance_decomposition_visualization(degrees, rmse_tr_bv, rmse_te_bv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = build_poly(mtX, 7)\n",
    "print(poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = range(10)\n",
    "ratio_train = 0.7\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = split_data(mtX, my, ratio_train, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmin(rmse_te_cv)\n",
    "degree_ri = degrees[idx]\n",
    "\n",
    "print(\"degree* ={dergee}\\n\\nrmse train={rmse_tr}\\n\\nrmse test={rmse_te}\".format(\n",
    "    degree=degree_ri, rmse_tr=rmse_tr_bv[idx], rmse_te=rmse_te_bv[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTHERS\n",
    "Cross-validation hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-1f562489fff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mk_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_k_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mrmse_tr_ri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_te_ri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ri'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\Machine-learning-Project-2019\\scripts\\implementations_master.py\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, x, k_indices, k_fold, degrees, lambdas, ml_function, max_iters, gamma, verbose)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mml_function\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ri'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m                     \u001b[0mw_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m                     \u001b[0mloss_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_te\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Machine-learning-Project-2019\\scripts\\implementations_master.py\u001b[0m in \u001b[0;36mridge_regression\u001b[1;34m(y, tx, lambda_)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[0maI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0maI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'DD->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'dd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "degree_ri = 7\n",
    "k_fold = 4\n",
    "lambdas = np.logspace(-12, -8, 10)\n",
    "degrees = range(10, 13)\n",
    "\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "rmse_tr_ri, rmse_te_ri = cross_validation(y, tX, k_indices, k_fold, degrees, lambdas, ml_function = 'ri', max_iters = 100, gamma = 0.05, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_visualization(degrees, rmse_tr_ri, rmse_te_ri, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.unravel_index(np.nanargmin(rmse_te_ri), rmse_te_ri.shape)\n",
    "lambda_ri = lambdas[idx[0]]\n",
    "degree_ri = degrees[idx[1]]\n",
    "\n",
    "print(\"lambda*={lambda_}\\n\\ndegree*={degree}\\n\\nrmse train={rmse_tr}\\n\\nrmse test={rmse_te}\".format(\n",
    "    lambda_=lambda_ri, degree=degree_ri, rmse_tr=rmse_tr_ri[idx], rmse_te=rmse_te_ri[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Bias-variance decomposition for complexity determination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(y==-1, 0, y)\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 1000\n",
    "#gammas = np.logspace(-10, -1, 20)\n",
    "gammas = np.logspace(-10, 0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_lr = np.empty(len(gammas))\n",
    "ws_lr = np.empty((len(gammas), len(initial_w)))\n",
    "for idx, gamma in enumerate(gammas):\n",
    "    (ws_lr[idx, :], losses_lr[idx]) = logistic_regression(y, tX, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the losses per gamma used\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(gammas, losses_lr)\n",
    "\n",
    "ax.set(xlabel='gamma', ylabel='loglikelihood',\n",
    "       title='Log likelihood per choice of learning rate')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w* =[ 1.63770625e-03 -5.19472491e-03 -1.72682046e-03  2.26710426e-03\n",
      " -1.11560122e-04  1.71688117e-03 -1.54745038e-04 -2.79954815e-05\n",
      " -8.38461056e-04 -2.51711457e-04 -1.35936286e-04  8.78782137e-05\n",
      " -9.49255117e-05  2.41049032e-03  3.55148970e-06 -3.67336981e-06\n",
      " -1.51052891e-03  1.87891008e-06  1.50302206e-05  1.91415798e-04\n",
      " -1.01609239e-05 -1.55314764e-03  5.76698514e-04 -1.44148676e-04\n",
      " -1.48843855e-04 -1.05398830e-03 -9.45848614e-05 -1.00229916e-04\n",
      " -1.15167154e-03]\n",
      "\n",
      "loglikelihood loss=5583.616679578695\n",
      "\n",
      "gamma=1.5998587196060573e-10\n"
     ]
    }
   ],
   "source": [
    "idx = np.nanargmin(losses_lr)\n",
    "\n",
    "w_lr = ws_lr[idx]\n",
    "gamma_lr = gammas[idx]\n",
    "\n",
    "print(\"w* ={w}\\n\\nloglikelihood loss={loss}\\n\\ngamma={gamma}\".format(\n",
    "    w=w_lr, loss=losses_lr[idx], gamma = gamma_lr))\n",
    "#loglikelihood loss=5663.039027226338\n",
    "#gamma=1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross-validation for hyperparameter determination***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "k_fold = 4\n",
    "degrees = range(1, 9)\n",
    "\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "loss_tr_lr, loss_te_lr = cross_validation(y, tX, k_indices, k_fold, degrees, \n",
    "                                          lambdas=[0], ml_function = 'lr', max_iters = 1000, gamma = gamma_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_visualization(degrees, loss_tr_lr, loss_te_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_te_lr = np.array(loss_te_lr)\n",
    "loss_tr_lr = np.array(loss_tr_lr)\n",
    "\n",
    "idx = np.nanargmin(loss_te_lr)\n",
    "\n",
    "degree_lr = degrees[idx]\n",
    "\n",
    "print(\"degree*={degree}\\n\\nloglikelihood train={loss_tr}\\n\\nloglikelihood test={loss_te}\".format(\n",
    "    degree=degree_ri, loss_tr=loss_tr_lr.flatten()[idx], loss_te=loss_te_lr.flatten()[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 1000\n",
    "gammas = np.logspace(-10, -1, 20)\n",
    "lambda_rlr =lambda_ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_rlr = np.empty(len(gammas))\n",
    "ws_rlr = np.empty((len(gammas), len(initial_w)))\n",
    "for idx, gamma in enumerate(gammas):\n",
    "    (w, loss) = reg_logistic_regression(y, tX, lambda_rlr, initial_w, max_iters, gamma)\n",
    "    losses_rlr[idx] = loss\n",
    "    ws_rlr[idx, :] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the losses per gamma used\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(gammas, losses_rlr)\n",
    "\n",
    "ax.set(xlabel='gamma', ylabel='loglikelihood',\n",
    "       title='Log likelihood per choice of learning rate')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.nanargmin(losses_rlr)\n",
    "\n",
    "w_rlr = ws_rlr[idx]\n",
    "gamma_rlr = gammas[idx]\n",
    "\n",
    "print(\"w* ={w}\\n\\nloglikelihood loss={loss}\\n\\ngamma={gamma}\".format(\n",
    "    w=w_rlr, loss=losses_rlr[idx], gamma = gamma_rlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***Cross-validation hyperparameter selection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "degree_rlr = 1\n",
    "k_fold = 4\n",
    "lambdas = np.logspace(-8, -2, 10)\n",
    "degrees = range(3, 12)\n",
    "\n",
    "k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tr_rlr, loss_te_rlr = cross_validation(y, tX, k_indices, k_fold, degrees, \n",
    "                                          lambdas, ml_function = 'rlr', max_iters = 500, gamma = gamma_rlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_visualization(degrees, loss_tr_rlr, loss_te_rlr, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.unravel_index(np.nanargmin(loss_te_rlr), loss_te_rlr.shape)\n",
    "lambda_rlr = lambdas[idx[0]]\n",
    "degree_rlr = degrees[idx[1]]\n",
    "\n",
    "print(\"lambda* ={lambda_}n\\ndegree*={degree}\\n\\nloglikelihood train={log_tr}\\n\\nloglikelihood test={log_te}\".format(\n",
    "    lambda_=lambda_rlr, degree=degree_rlr, log_tr=loss_tr_rlr[idx], log_te=loss_te_rlr[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
