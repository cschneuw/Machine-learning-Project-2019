{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change later : Simple data description \n",
    "- all variables are floating point, except PRI_jet_num which is integer\n",
    "- variables prefixed with PRI (for PRImitives) are “raw” quantities about the bunch collision as measured by the detector.\n",
    "- variables prefixed with DER (for DERived) are quantities computed from the primitive features, which were selected by the physicists of ATLAS.\n",
    "- it can happen that for some entries some variables are meaningless or cannot be computed; in this case, their value is −999.0, which is outside the normal range of all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape = (250000,)\n",
      "tX shape =(250000, 30)\n",
      "ids shape = (250000,)\n"
     ]
    }
   ],
   "source": [
    "print('y shape = ' + str(y.shape) + '\\ntX shape =' + str(tX.shape) + '\\nids shape = ' + str(ids.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the data:\n",
    "- `y` (N) is composed of the labels (-1 or 1) of all the samples.  \n",
    "- `tX` (N x F) is composed of the values of the features (F) for all samples (N)  \n",
    "- `ids` (N) is composed of all the index (100000-349999) of the samples (N)  \n",
    "  \n",
    "Moreover, the number of features is 30 (F=30) and the number of samples is 250'000 (N=250'000). Non recorded data has value `-999`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove categorical data\n",
    "tX = np.delete(tX, 22, axis=1)\n",
    "# keep only columns that do not have too much missing data\n",
    "tX, rmX = train_data_formatting(tX, degree = 1, cutoff = 0.7, \n",
    "                      imputation = impute_median, interaction = False)\n",
    "# standarize the data\n",
    "rmX = np.append(rmX, 22)\n",
    "tX = np.apply_along_axis(standardize, 1, tX)\n",
    "#y = y[0:50000]\n",
    "#tX = tX[0:50000, :]\n",
    "y = np.where(y==-1, 0, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 23)\n",
      "[ 4  5  6 12 25 26 27 22]\n"
     ]
    }
   ],
   "source": [
    "print(tX.shape)\n",
    "print(rmX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Least squares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w* =[-7.59283089 19.6694143  19.39821666 19.35518478 19.62639834 28.63972958\n",
      " 19.53006013  9.74944854 16.29645991 20.77669879 29.93140738 19.60364672\n",
      " 19.57699065 29.79115422 19.56696225 19.60787189 19.70600927 19.56557262\n",
      " 19.62541216 19.67129904 19.59251008 19.55347643 29.4901593 ]\n",
      "\n",
      "mse=0.08499426980625849\n"
     ]
    }
   ],
   "source": [
    "(w_ls, loss_ls) = least_squares(y, tX)\n",
    "\n",
    "print(\"w* ={w}\\n\\nmse={loss}\".format(w=w_ls, loss=loss_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Least squares with Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters\n",
    "\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 100\n",
    "gammas = np.logspace(-6, 0, 20)\n",
    "\n",
    "losses_gd = np.empty(len(gammas))\n",
    "ws_gd = np.empty((len(gammas), len(initial_w)))\n",
    "\n",
    "for idx, gamma in enumerate(gammas):\n",
    "    (w, loss) = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "    losses_gd[idx] = loss\n",
    "    ws_gd[idx, :]=w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEaCAYAAAAcz1CnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxddX3/8dd7tsxkTyAMZCGJENSwkwC1CsSFihtY6wK2SCwabYv+ql2A1lKK+qvVWqxKaxEVxZ9GS63GGI3VZgriliCLJjQQlpBJWLInk3WWz++PcyY5ubmz3JmczM2c9/Mx9zHnfM/3nPP9nHvu/dyzKyIwM7PiqhnqBpiZ2dByIjAzKzgnAjOzgnMiMDMrOCcCM7OCcyIwMys4JwKzo0xSSDp1AOOdLKlNUm0e7ephns2S7pG0U9Inywy/U9JHjlZ7Sub9fUnXDMW8h5u6oW7AsUTSU8BkYHJEbMqUPwicDcyMiKeGpnU23EXE08DoozzbBcAmYGxU2UVHEfGaoW5DN0ktwFcj4o6hbstAeIugck8CV3X3SDoTaBq65gwtSbn+mCg3/UrnORRtHEamA6uOdhKopmVaTW3JixNB5e4C3pHpvwb4SraCpBGS/lHS05Kek/Q5SU3psAmSFkvaKGlr2j01M26LpA9Lui/dHP+hpOPLNUTS8en42yRtkXSvpJp02LmSfpVO4xuSFnZvwkuaL+knJdM6sLtC0uskPSBph6R1km7O1JuR1r1W0tPAf6flvyXpp2lbHpI0r6cFKGmypP9Il8GTkt6fGXazpLslfVXSDmB+D2UjJH1K0ob09SlJI9JpzJPUKul6Sc8CXyrThvnpMv6MpO2S/lfSKzPDx0n6gqRnJK2X9JHuXTKZcW+VtAW4ucz0ayX9laTH0/fgfknTMlVeJemxdB24TZLS8WokfUjSWknPS/qKpHEly74u7Z8o6Utp/FslfTsz/9dLejB9P34q6axe3o/flrQ8XQ7LJf12Wn4nyfr9l0p2Sb2qp2n0Z76Sbsgsj1WSfrfM+3FgmXavp0o+S1vTdeU1mXFaJL0rM35vdWfq4C6uH6XL/Ks9xHDY+qNePreSPgpcBHw2XU6fTctfJOm/lHw2V0t6a1/Lb8hEhF/9fAFPAa8CVgMvBmqBdSS/mgKYkdb7FLAImAiMAb4L/H067Djg94CR6bB/B76dmUcL8DhwGsmWRgvwsR7a8/fA54D69HURIKABWAt8IC1/M9AOfCQdbz7wk5JpBXBq2j0POJPkh8JZwHPAG9NhM9K6XwFGpW2cAmwGXpuOc2naP6lMm2uA+4Gb0na+AHgCeHU6/Oa0rW9M6zb1UHYL8HPgBGAS8FPgw5n2dwD/AIwAmsq0Y35ap3sZvQ3YDkxMh38b+Lc0xhOAXwLvKRn3fSS7V8tN/y+AXwMvTN+Ts4HjMst6MTAeOBnYCFyWDvtDYE26XEYD3wLuKln2dWn/94BvABPSGC5Jy88DngcuJFlHryFZd0eUaedEYCtwdRrLVWl/d1vvJF1velgHDwzva77AW0h2rdaky3sXcFJPyzQtawfenU7vj4ANgDKflXdlxu+t7s+AfyRZ514G7CDZlVMupnmUrD/073P7rkz/KJLvhnem8ZxHsovt9KH+Hisb81A34Fh6cTARfIjkS/gy4L/SNzrSD6rSFfyUzHgvAZ7sYZrnAFtLVqgPZfr/GPhBD+PeAnyH9As8U35x9kOQlv2UfiaCMvP5FHBr2j0jrfuCzPDrSb+sMmVLgWvKTOtC4OmSshuBL6XdNwP3lAwvV/Y48NpM/6uBp9LuecB+oLGX93J+mWX0S5IvxGZgH5kveJIvyGWZcZ/uadppndXAFT0MC+Blmf5vAjek3T8G/jgz7IUkX3B1mWVfB5wEdAETykz/X0mTYkl7LilT92rglyVlPwPmp9130v9E0O/5psMe7F5G5ZZpWrYm0z8yjf/EzGflXX3VJUm2HcDIzPCv0nsi6Gv9Kfe5zSaCtwH3lozzb8Df9rbeDNVr2O/7ysldwD3ATEp2C5H8Oh0J3J9u7UOSHLp3K4wEbiVJIhPS4WMk1UZEZ9r/bGZ6u+n5AOEnSL4kf5jO6/aI+BjJr671ka59qbX9DU7ShcDHgDNIfkGNIPkFlLUu0z0deIukN2TK6oFlZSY/HZgsaVumrBa4t4dp91Q2mUNjWpuWddsYEXvLTCer3DKanLaxHngm8x7WlLShXBuzppEkq5709B6Xi6uOJDmVTn9LRGwtM+3pwDWS3pcpa+DQ5dOtdH7d85zSS9t70ut8Jb0D+CBJQoMk5uxuz3LL9MByiojd6fvR0+ehp7rHkyyr3SXzmkbPDll/+vm5zZoOXFiynteRfHdUHSeCAYiItZKeJNkVcm3J4E3AHpJNwPVlRv8zkl95F0bEs5LOAR4gSRaVtmNnOr0/k3Q6sEzScuAZYIokZb7oTubgF9MukmQFgKQTSyb9NeCzwGsiYq+kT3HoBxaSX1vd1pFsEby7H81eR7J1NKu30PpRtoHkw7Yy7T85LettGqXKLaNFaRv3AcdHREcFbcxaB5wC/KYf7cjqjqtb96/Z54CpmfJ1wERJ4yMi+2XTPeyjEfHRAcyve54/qKjVfcxX0nTg88ArgZ9FRKeSs+2y631eB6SfIVlWIzPJoLckUK4tfX1uS+uvA/4nIi4dRLuPGh8sHrhrgVdExK5sYUR0kazwt0o6AUDSFEmvTquMIUkU2yRNBP52oA1ID8ydmh5o3AF0pq+fkXx5vF9SnaQ3ARdkRn0IOF3SOZIaOfxg5xiSX1B7JV0AvL2PpnwVeIOkVys5SNqYHnCbWqbuL4Ed6YG4prT+GZLOrzD8rwMfkjRJycH0m9J2VOIEkmVUL+ktJMd9lkTEM8APgU9KGqvkAO4pki6pYNp3AB+WNEuJsyQd18+4PpAe3BwN/F/gG6UJKW3j94F/SQ9k1ku6OB38eeC9ki5M5z1KyQkAY8rMbwlwmqS3p+vK24DZJMcwKtXbfEeRfFluBJD0TpItztxFxFpgBckB6AZJLwHe0Mdopfr63D5Hclyn22KS5Xp1+t7USzpf0osHGEaunAgGKCIej4gVPQy+nuSA38+VnOXyI5JfE5Dsb28i2XL4OQP75dVtVjrtNpIv/3+JiJaI2A+8iWS/6VaS/ZXfyrT9UZLjCz8CHgN+cuhk+WPgFkk7Sb5gv9lbIyJiHXAF8FckH/R1JAdLD1u/0s3oN5DsY32SZDncAYzrf9gAfITkw/0wyUHZX6VllfgFyTLcBHwUeHNEbE6HvYNkt8YqkmV4N8l++f76J5Ll9kOSJP0F+nea8Rc5uOvxSWAvyQHUcq4mOX7wvyQHaf8UIF0v302yVbeVZF2cX24CabyvJ/nFuxn4S+D1kblOpr96m29ErAI+SbKePkdyMsJ9lc5jEH6f5FjdZpL15BskW3391dfn9p+BN6dnFH063Vr/HeBKkq2uZzl48LnqKCKvrTGrJkpOBWyNiA8NdVuqgaT5JAf3XjbUbbGjT9I3gP+NiAFvkQ8n3iIws2Ev3S1zSrqb7zKSLdhv9zVeUeSaCCRdll5IsUbSDWWGnyxpmZKLlx6W9No822NmhXUiySmebcCngT+KiAeGtEVVJLddQ0quwnyU5OKiVmA5cFW6r7C7zu3AAxHxr5Jmkxyom5FLg8zMrKw8twguILnA44n04OVCks2xrADGpt3jOPT0PzMzOwryvI5gCodeINJKclVp1s0kF0O9j+T0sj7vZWJmZkdWnomg3AVSpfuhrgLujIhPpuf23iXpjPRc/IMTkhaQ3A6XpqamOdOm9XUtSHldXV3U1AyP4+OOpfoMlzig+mJp74L1bV1MahKj6iu79rLaYhmMwcTy6KOPboqISWUH5nXvCpJzdpdm+m8EbiypsxKYlul/Ajiht+nOmTMnBmrZsmUDHrfaOJbqM1ziiKi+WFY/uyOmX784Fj+0oeJxqy2WwRhMLMCK6OF7Nc80uRyYlV4h2UByYcWikjpPk1xyTnrFXSPplYdmZnZ05JYIIrkk/jqSu1A+AnwzIlZKukXS5Wm1PwPeLekhkkvr56eZy8zMjpJcbzoXEUtI7mWSLbsp070KeGmebTAzs94NjyMoZmY2YE4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBZdrIpB0maTVktZIuqHM8FslPZi+HpW0Lc/2mJnZ4XJ7ZrGkWuA24FKgFVguaVH6nGIAIuIDmfrvA87Nqz1mZlZenlsEFwBrIuKJiNgPLASu6KX+VcDXc2yPmZmVkWcimAKsy/S3pmWHkTQdmAn8d47tMTOzMnLbNQSoTFn0UPdK4O6I6Cw7IWkBsACgubmZlpaWATWora1twONWG8dSfYZLHFB9sazf2QXAylUrGbVldUXjVlssg5FbLBGRywt4CbA0038jcGMPdR8Afrs/050zZ04M1LJlywY8brVxLNVnuMQRUX2xrH52R0y/fnEsfmhDxeNWWyyDMZhYgBXRw/dqnruGlgOzJM2U1EDyq39RaSVJLwQmAD/LsS1mZtaD3BJBRHQA1wFLgUeAb0bESkm3SLo8U/UqYGGasczM7CjL8xgBEbEEWFJSdlNJ/815tsHMzHrnK4vNzArOicDMrOCcCMzMCs6JwMys4JwIzMwKzonAzKzgnAjMzArOicDMrOCcCMzMCs6JwMys4JwIzMwKzonAzKzgnAjMzArOicDMrOCcCMzMCs6JwMys4JwIzMwKzonAzKzgnAjMzAou10Qg6TJJqyWtkXRDD3XeKmmVpJWSvpZne8zM7HC5PbxeUi1wG3Ap0Aosl7QoIlZl6swCbgReGhFbJZ2QV3vMzKy8PLcILgDWRMQTEbEfWAhcUVLn3cBtEbEVICKez7E9ZmZWRm5bBMAUYF2mvxW4sKTOaQCS7gNqgZsj4gelE5K0AFgA0NzcTEtLy4Aa1NbWNuBxq41jqT7DJQ6ovljW7+wCYOWqlYzasrqicastlsHIK5Y8E4HKlEWZ+c8C5gFTgXslnRER2w4ZKeJ24HaAuXPnxrx58wbUoJaWFgY6brVxLNVnuMQB1RfLo8/thPvu4fTZpzPvrJMqGrfaYhmMvGLJc9dQKzAt0z8V2FCmzncioj0ingRWkyQGMzM7SvJMBMuBWZJmSmoArgQWldT5NvByAEnHk+wqeiLHNpmZWYncEkFEdADXAUuBR4BvRsRKSbdIujytthTYLGkVsAz4i4jYnFebzMzscHkeIyAilgBLSspuynQH8MH0ZWZmQ8BXFpuZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcHlmggkXSZptaQ1km4oM3y+pI2SHkxf78qzPWZmdrjcnlksqRa4DbgUaAWWS1oUEatKqn4jIq7Lqx1mZta7PLcILgDWRMQTEbEfWAhckeP8zMxsAHLbIgCmAOsy/a3AhWXq/Z6ki4FHgQ9ExLrSCpIWAAsAmpubaWlpGVCD2traBjxutXEs1We4xAHVF8v6nV0ArFy1klFbVlc0brXFMhi5xRIRubyAtwB3ZPqvBj5TUuc4YETa/V7gv/ua7pw5c2Kgli1bNuBxq41jqT7DJY6I6otl9bM7Yvr1i2PxQxsqHrfaYhmMwcQCrIgevlfz3DXUCkzL9E8FNpQkoc0RsS/t/TwwJ8f2mJlZGXkmguXALEkzJTUAVwKLshUknZTpvRx4JMf2mJlZGbkdI4iIDknXAUuBWuCLEbFS0i0kmyiLgPdLuhzoALYA8/Nqj5mZlZfnwWIiYgmwpKTspkz3jcCNebbBzMx65yuLzcwKzonAzKzgnAjMzArOicDMrOCcCMzMCs6JwMys4JwIzMwKzonAzKzgnAjMzArOicDMrOCcCMzMCs6JwMys4JwIzMwKrtdEIOkPMt0vLRnmB86bmQ0DfW0RfDDT/ZmSYX94hNtiZmZDoK9EoB66y/WbmdkxqK9EED10l+s3M7NjUF9PKHuRpIdJfv2fknaT9r8g15aZmdlR0VciePFgJi7pMuCfSZ5ZfEdEfKyHem8G/h04PyJWDGaeZmZWmV4TQUSszfZLOg64GHg6Iu7vbVxJtcBtwKVAK7Bc0qKIWFVSbwzwfuAXlTffzMwGq6/TRxdLOiPtPgn4DcnZQndJ+tM+pn0BsCYinoiI/cBC4Ioy9T4MfBzYW2njzcxs8PraNTQzIn6Tdr8T+K+IeEf6K/4+4FO9jDsFWJfpbwUuzFaQdC4wLSIWS/rzniYkaQGwAKC5uZmWlpY+ml1eW1vbgMetNo6l+gyXOKD6Ylm/swuAlatWMmrL6orGrbZYBiOvWPpKBO2Z7lcCnweIiJ2SuvoYt9zppQfONJJUA9wKzO+rkRFxO3A7wNy5c2PevHl9jVJWS0sLAx232jiW6jNc4oDqi+XR53bCffdw+uzTmXfWSRWNW22xDEZesfSVCNZJeh/Jr/nzgB8ASGoC6vsYtxWYlumfCmzI9I8BzgBaJAGcCCySdLkPGJuZHT19XUdwLXA6ya/2t0XEtrT8t4Av9THucmCWpJmSGoArgUXdAyNie0QcHxEzImIG8HPAScDM7Cjr66yh54H3lilfBizrY9yO9H5ES0lOH/1iRKyUdAuwIiIW9Ta+mZkdHb0mAkm9fllHxOV9DF8CLCkpu6mHuvN6m5aZmeWjr2MELyE58+frJOf5+/5CZmbDTF+J4ESSC8KuAt4OfA/4ekSszLthZmZ2dPR6sDgiOiPiBxFxDckB4jUkZ/m876i0zszMctfXFgGSRgCvI9kqmAF8GvhWvs0yM7Ojpa+DxV8mOdf/+8DfZa4yNjOzYaKvLYKrgV3AacD70wu/IDloHBExNse2mZnZUdDXdQR+uL2Z2TDnL3ozs4JzIjAzKzgnAjOzgnMiMDMrOCcCM7OCcyIwMys4JwIzs4JzIjAzKzgnAjOzgnMiMDMrOCcCM7OCyzURSLpM0mpJayTdUGb4eyX9WtKDkn4iaXae7TEzs8Pllggk1QK3Aa8BZgNXlfmi/1pEnBkR5wAfB/4pr/aYmVl5eW4RXACsiYgnImI/sBC4IlshInZkekcBkWN7zMysDEXk890r6c3AZRHxrrT/auDCiLiupN6fAB8EGoBXRMRjZaa1AFgA0NzcPGfhwoUDalNbWxujR48e0LjVxrFUn+ESB1RfLOt3dvHX9+3hj88ZwQUn9vlgxUNUWyyDMZhYXv7yl98fEXPLDoyIXF7AW4A7Mv1XA5/ppf7bgS/3Nd05c+bEQC1btmzA41Ybx1J9hkscEdUXy+pnd8T06xfH4oc2VDxutcUyGIOJBVgRPXyv5rlrqBWYlumfCmzopf5C4I05tsfMzMrIMxEsB2ZJmimpAbgSWJStIGlWpvd1wGG7hczMLF+V7WyrQER0SLoOWArUAl+MiJWSbiHZRFkEXCfpVUA7sBW4Jq/2mJlZebklAoCIWAIsKSm7KdP9f/Kcv5mZ9c1XFpuZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcHlmggkXSZptaQ1km4oM/yDklZJeljSjyVNz7M9ZmZ2uNwSgaRa4DbgNcBs4CpJs0uqPQDMjYizgLuBj+fVHjMzKy/PLYILgDUR8URE7AcWAldkK0TEsojYnfb+HJiaY3vMzKyMPBPBFGBdpr81LevJtcD3c2yPmZmVUZfjtFWmLMpWlP4AmAtc0sPwBcACgObmZlpaWgbUoLa2tgGPW20cS/UZLnFA9cWyfmcXACtXrWTUltUVjVttsQxGbrFERC4v4CXA0kz/jcCNZeq9CngEOKE/050zZ04M1LJlywY8brVxLNVnuMQRUX2xrH52R0y/fnEsfmhDxeNWWyyDMZhYgBXRw/dqnruGlgOzJM2U1ABcCSzKVpB0LvBvwOUR8XyObTEzsx7klggiogO4DlhK8ov/mxGxUtItki5Pq30CGA38u6QHJS3qYXJmZpaTPI8REBFLgCUlZTdlul+V5/zNzKxvvrLYzKzgct0iqCatW3ezanMnDWs2gUAIKTm1qaZGCJCATLl0sLy7fo1ETU36X6JGB7ulZFq1abmyw2uS7rqaGupqRV2NkMqdWGVmdnQVJhEsfvgZPr58Lyz/xVA35YDaGlFbI+rT/3W1NdTVJEniQHetqK1JuutrxYi6Whrra9i5bS/fee5BGutr0rLaTHfNgf7GdNiI+hpGNtQxtrGO8SMbGNtYR12tNwjNrECJ4PKzJ6PNT3H2OecQAUGQ/hEBXRFpd/KftE4Eaf20TiR1OiPoSru7IujqSoZ3peVdmeGdXWlZV9DRFXR2ddHemZR3dAUdnV1pedDR1UVHZ1peUre9s4t97V1s3rWfzbu6eH7tVva2dyavji72d3RVtEzGjKhjbFM945rqGT/y4P+xTfWMb2o4pHxcUz0TRjXQPGaEE4jZMFOYRDB5fBMvnFjLb73guKFuyhHR0tLCvHnzDinr6gr2dXSliaGTve1dBxNFexd72jvYsaeDbbv3s31PB9v27Gf7nna2725n+552Hnu+7UD//s7ySaW2Rkwe38jU8SOZNrGJqRNGMnVCE9MmJv+bxzRSU+NdXmbHksIkgiKoqRFNDbU0NdQOajoRwd72rgOJYluaKDa37Wf9tt2s27KH1q27aVm9ked37jtk3IbaGiaPbzyQGLKJYvrEkRw3esSg2mZmR54TgR1G6k4oTZw0rqnXunvbO1m/bQ/rtuymdese1m1N/rdu2c0PN+xg8679h9Q/aVwjZ08dz9nTxnP21HGcOXVcnqGYWT84EdigNNbXcsqk0ZwyaXTZ4bv3dySJYetunti4i4dbt/Nw6zZ+sPJZIDkj68SR4iXPP8g508Zz1tTxvPikMYyoG9xWjZn1nxOB5WpkQx2nNY/htOYxvOJFB8u37trPw+u38/C6bfz4wce559FNfOtX6wGorxWzTxrLWZkth1MmjfaxB7OcOBHYkJgwqoFLTpvEJadN4sza9VxyySU8s30vD63bxkOt23lo3Tb+84H13PXztQCMHlHHWVPH8dJTj+fiWZM4ffJYJwazI8SJwKqCJCaPb2Ly+CZec+ZJQHIW1BOb2nhwXZIY7l+7lU8sXc0nlq5m4qgGXnbq8Vw063guPm0SzWMbhzgCs2OXE4FVrZoaceoJYzj1hDG8eU7y8LqNO/dx35pN3PPoRu55bBOLHtoAwAubx3Dxacdz0axJXDBzIo31PsZg1l9OBHZMmTRmBG88dwpvPHcKEcEjz+zk3sc2cs9jG/nyT9fy+XufZERdDRfMnMglp03iolmTOK15tG/nYdYLJwI7Zkli9uSxzJ48lvdccgp79nfyiyc3c8+jm7j3sY185HuPAI/QPHYEF82axEWzjueCmRP7PCXWrGicCGzYaGqoZd4LT2DeC08AYMO2PfzksU38z2Mb+dEjz3H3/a0ATBnfxNwZE5g7YyJzp0/gtOYx1PrAsxWYE4ENW5PHN/HW86fx1vOn0dkVrNqwgxVrt7Diqa387PHNfOfB5PjCmMY6zjt5AufPmMCc6RM5Z9r4QV+dbXYscSKwQqitEWemVzK/86UziQhat+5h+VNbWLF2Kyue2sI//nAjAHU14owp45g7Pd1qmDGB431rDBvGnAiskCQxbeJIpk0cyZvOS85I2rZ7P796eivLn9rK/U9t5Ss/X8sdP3kSgBnHjeS8kycwdUITJ4xtpHlsI81jR9A8tpHjRjX4jqx2TMs1EUi6DPhnoBa4IyI+VjL8YuBTwFnAlRFxd57tMevN+JENvOJFzbziRc0A7Ovo5Dfrd7Ai3Wq47/FNbNy5j644dLwawfGjRzBS7Zy6dnmSKMYcTBQnpP8njmzwRXBWlXJLBJJqgduAS4FWYLmkRRGxKlPtaWA+8Od5tcNsoEbU1TJn+gTmTJ/Ae9Kyjs7keRDP7djLczv28dyOvTyfdj/y1AbWb9vLA09vO+xme5Dsnho9ou7Aa9SIWkY31jN6RG3aX8eY9P+oEXWMaaxjVEMdoxsPjjOmsY4xjfU01HkLxI6cPLcILgDWRMQTAJIWAlcABxJBRDyVDqvsiSpmQ6SutibdLXT4lcwtLVuYN+8iAPZ3dLGx7dBE8fzOvbTt7WDnvg527etg175Otu9pZ8O2PbTtTcra9ncQcdikD9NUX8uYxuTBQmPT5HBodx1jG+szdZJh45rqGTey3jf1s0PkmQimAOsy/a3AhTnOz6xqNNTVMGV8E1PGV3bNQldXsKe9k137DiaMtr0dtO1LXjv3drBjTzs79yX/d+xtZ+fe5GFDT2/Zzc69ybMj2jt7zyaN9TXJE+jSJ9GNLXka3fOt7Wx/cP2B/u7X2KZ66n08ZNjJMxGU2xnaj986ZSYkLQAWADQ3N9PS0jKgBrW1tQ143GrjWKpPnnE0ABPTF7XAyPR1mHoi6mjvgt0dwe725P+e9mBXB+xuD3YdeHWyu2M327cHz2zmQPm+zmRKX33kwbJtGVELI+vEyPru/2JkHen/cv1JvaZ60VgL9TVUfKX3+p3JToOVq1YyasvqisYdLusX5BdLnomgFZiW6Z8KbBjIhCLiduB2gLlz50bpIxr7q9zjHY9VjqX6DJc49nd08f0f/w+nn3s+20ueUrdjTwc79rYf2BrZsaeDnfvaWb+ngx3bk/LSg+nlNNUnT9Jrqq+lsb4m013LyLS7qSHpb6qvZVdXB7CW02efzryzTqoonuHyvkB+seSZCJYDsyTNBNYDVwJvz3F+ZnYENNTVMG6EOPWE8g8b6k1EsGt/5yGJ4mB3O3vau9iTPkd7z/5Odu9Pu9P+nXs72Lhz34H+7rrtnUFtjThxnO8ym4fcEkFEdEi6DlhKsjH7xYhYKf8ZHSYAAAd7SURBVOkWYEVELJJ0PvCfwATgDZL+LiJOz6tNZpYv6eCZUZM5cvd0au/sorMrfFfZnOR6HUFELAGWlJTdlOleTrLLyMysR/W1NTgH5MeH/83MCs6JwMys4JwIzMwKzonAzKzgnAjMzArOicDMrOCcCMzMCs6JwMys4JwIzMwKzonAzKzgnAjMzArOicDMrOCcCMzMCs6JwMys4JwIzMwKzonAzKzgnAjMzArOicDMrOCcCMzMCi7XRCDpMkmrJa2RdEOZ4SMkfSMd/gtJM/Jsj5mZHS63RCCpFrgNeA0wG7hK0uySatcCWyPiVOBW4B/yao+ZmZWX5xbBBcCaiHgiIvYDC4ErSupcAXw57b4beKUk5dgmMzMrUZfjtKcA6zL9rcCFPdWJiA5J24HjgE3ZSpIWAAvS3jZJqzODxwHb+9l9fOm0K5SdZqXDyw0rLTtasfQVR191emt3X/3d3dmyoYql0vektL80lrzXr97qDOf1q1zZsRDLkV6/YHCxTO9xSETk8gLeAtyR6b8a+ExJnZXA1Ez/48BxFc7n9v52AysGGdPtAx1eblhp2dGKpa84Ko2lkv5M+7NlQxJLpe9JX7HkvX4dyViOpfXrWI3lSK9fR2Id6+mV566hVmBapn8qsKGnOpLqSDLflgrn890Kuwejr+n0NrzcsNKyoxVLf6ZRSSyV9H+3hzoDNZhYKn1PSvuP5ViOpfWrXNmxEEu1rV89UppljvyEky/2R4FXAuuB5cDbI2Jlps6fAGdGxHslXQm8KSLemkuDkvmtiIi5eU3/aHIs1We4xAGOpVrlFUtuxwgi2ed/HbAUqAW+GBErJd1CsnmzCPgCcJekNSRbAlfm1Z7U7TlP/2hyLNVnuMQBjqVa5RJLblsEZmZ2bPCVxWZmBedEYGZWcE4EZmYF50SQklQj6aOSPiPpmqFuz2BImifpXkmfkzRvqNszGJJGSbpf0uuHui2DIenF6ftxt6Q/Gur2DIakN0r6vKTvSPqdoW7PYEh6gaQvSLp7qNtSqfSz8eX0vfj9wUxrWCQCSV+U9Lyk35SU93rTuxJXkFzp3E5yfcOQOEKxBNAGNDJEsRyhOACuB76ZTyv750jEEhGPRMR7gbcCQ3Yq4xGK5dsR8W5gPvC2HJvbqyMUyxMRcW2+Le2/CmN6E3B3+l5cPqgZ53GV2tF+ARcD5wG/yZTVklyp/AKgAXiI5OZ3ZwKLS14nADcA70nHvfsYj6UmHa8Z+H/HcByvIjmleD7w+mP5PUnHuRz4Kcn1NMd0LOl4nwTOGyaxDNlnfhAx3Qick9b52mDmm+e9ho6aiLinzC2sD9z0DkDSQuCKiPh74LDdDJJagf1pb2d+re3dkYglYyswIo929uUIvScvB0aRrPR7JC2JiK5cG17GkXpPIrl2ZpGk7wFfy6/FPTtC74uAjwHfj4hf5dvinh3hz0pVqCQmkq39qcCDDHLvzrBIBD3oz03vsr4FfEbSRcA9eTZsACqKRdKbgFcD44HP5tu0ilQUR0T8NYCk+cCmoUgCvaj0PZlHsik/AliSa8sqV+ln5X0kW2vjJJ0aEZ/Ls3EVqvR9OQ74KHCupBvThFFteorp08BnJb2OQd6GYjgngnK3s+7x6rmI2E3yfIRqVGks3yJJbNWmojgOVIi488g3ZdAqfU9agJa8GjNIlcbyaZIvoWpUaSybgffm15wjomxMEbELeOeRmMGwOFjcg/7c9O5YMVxiGS5xgGOpVsMplm65xzScE8FyYJakmZIaSA46LhriNg3UcIlluMQBjqVaDadYuuUf01AfJT9CR9q/DjzDwVM/r03LX0tyB9THgb8e6nYWKZbhEodjqd7XcIplqGPyTefMzApuOO8aMjOzfnAiMDMrOCcCM7OCcyIwMys4JwIzs4JzIjAzKzgnAjOzgnMiMDMruOF80zmzfpP0N8Dvk9zlcRNwP7AdWEByD/g1wNURsVvSncAe4EXAdJIbf10DvAT4RUTMT6fZBtxGcqfOrcBfAR8HTgb+NCIWpbccvovkdtsA10XET/ON1uxQ3iKwwpM0F/g94FySW0V3P0HsWxFxfkScDTzCoXennQC8AvgAyS2AbwVOB86UdE5aZxTQEhFzgJ3AR4BLgd8FbknrPA9cGhHnkTztq1rv6mnDmLcIzOBlwHciYg+ApO57u58h6SMkz3UYDSzNjPPdiAhJvwaei4hfp+OuBGaQPCxkP/CDtP6vgX0R0Z6OMyMtrye5p/w5JA9EOi2fEM165kRgVv5+7wB3Am+MiIfSh+PMywzbl/7vynR393d/rtrj4M28DtSLiC5J3XU+ADwHnE2yhb53wFGYDZB3DZnBT4A3SGqUNBp4XVo+BnhGUj3J8YM8jAOeieTpa1eTPJ/W7KjyFoEVXkQsl7SI5KHga4EVJAeK/wb4RVr2a5LEcKT9C/Afkt4CLAN25TAPs175NtRmgKTREdEmaSTJM6sXxBA+mN3saPIWgVnidkmzgUbgy04CViTeIjAzKzgfLDYzKzgnAjOzgnMiMDMrOCcCM7OCcyIwMys4JwIzs4L7//eH5V/32OtkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the losses per gamma\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(gammas, losses_gd)\n",
    "\n",
    "ax.set(xlabel='gamma', ylabel='MSE',\n",
    "       title='Mean square error per choice of learning rate')\n",
    "ax.grid()\n",
    "ax.set_ylim([0, 0.8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w* =[-0.00691905  0.06815533 -0.21071341  0.00440407  0.04080694 -0.00433785\n",
      " -0.0327805   0.08147202 -0.01109581 -0.00181672  0.10617811 -0.00658096\n",
      " -0.00692606 -0.03297125 -0.00656471 -0.00617559 -0.01756861 -0.00643702\n",
      "  0.02855037  0.03912669 -0.00649524 -0.0065453  -0.00476545]\n",
      "\n",
      "mse=0.09083708553081768\n",
      "\n",
      "gamma=0.05455594781168514\n"
     ]
    }
   ],
   "source": [
    "idx = np.nanargmin(losses_gd)\n",
    "\n",
    "w_gd = ws_gd[idx]\n",
    "gamma_gd = gammas[idx]\n",
    "\n",
    "print(\"w* ={w}\\n\\nmse={loss}\\n\\ngamma={gamma}\".format(\n",
    "    w=w_gd, loss=losses_gd[idx], gamma=gamma_gd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Least squares with Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 100\n",
    "gammas = np.logspace(-6, 0, 20)\n",
    "\n",
    "losses_sgd = np.empty(len(gammas))\n",
    "ws_sgd = np.empty((len(gammas), len(initial_w)))\n",
    "for idx, gamma in enumerate(gammas):\n",
    "    (w, loss) = least_squares_SGD(y, tX, initial_w, max_iters, gamma)\n",
    "    losses_sgd[idx] = loss\n",
    "    ws_sgd[idx,:] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the losses per gamma used\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(gammas, losses_sgd)\n",
    "\n",
    "ax.set(xlabel='gamma', ylabel='MSE',\n",
    "       title='Mean square error per choice of learning rate')\n",
    "ax.grid()\n",
    "ax.set_ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w* =[-0.0095231   0.03060685 -0.07288514  0.00378948  0.03024146 -0.00850982\n",
      " -0.00745647  0.04680329 -0.01086743 -0.00818582  0.02049885 -0.00946827\n",
      " -0.01028022 -0.01856037 -0.00986801 -0.00918502 -0.01888639 -0.01013164\n",
      "  0.03427737  0.03178682 -0.00913879 -0.01026777  0.02521011]\n",
      "\n",
      "mse=0.10024093381610087\n",
      "\n",
      "gamma=0.00615848211066026\n"
     ]
    }
   ],
   "source": [
    "idx = np.nanargmin(losses_sgd)\n",
    "\n",
    "w_sgd = ws_sgd[idx]\n",
    "gamma_sgd = gammas[idx]\n",
    "\n",
    "print(\"w* ={w}\\n\\nmse={loss}\\n\\ngamma={gamma}\".format(\n",
    "    w=w_sgd, loss=losses_sgd[idx], gamma=gamma_sgd ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge regression**\n",
    "\n",
    "For ridge regression, we have two parameters to optimize, the lambda (penality) and degree (complexity). To do so, we use a cross validation and bias-variance decomposition respectively. \n",
    "\n",
    "As the two are interdependent, we can just run them in a loop (each cells after the others, so first the cross-validation, then biais-variance decomposition, again cross-validation, etc.) to have the best parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross-validation hyperparameter selection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_visualization(lambds, loss_tr, loss_te):\n",
    "    \"\"\"visualization the curves of train error and test error.\"\"\"\n",
    "    plt.semilogx(lambds, loss_tr, marker=\".\", color='b', label='train error')\n",
    "    plt.semilogx(lambds, loss_te, marker=\".\", color='r', label='test error')\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "degree_ri = 1\n",
    "k_fold = 4\n",
    "lambdas = np.logspace(-12, 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "rmse_tr_cv = np.empty(len(lambdas))\n",
    "rmse_te_cv = np.empty(len(lambdas))\n",
    "\n",
    "for index_lambda, lambda_ in  enumerate(lambdas):\n",
    "    l_rmse_tr = np.empty(k_fold)\n",
    "    l_rmse_te = np.empty(k_fold)\n",
    "    for k in range(k_fold):\n",
    "        loss_tr, loss_te = cross_validation(y, tX, k_indices, k, lambda_, degree_ri)\n",
    "        l_rmse_tr[k] = np.sqrt(2*loss_tr)\n",
    "        l_rmse_te[k] = np.sqrt(2*loss_te)\n",
    "    rmse_tr_cv[index_lambda] = np.mean(l_rmse_tr)\n",
    "    rmse_te_cv[index_lambda] = np.mean(l_rmse_te)\n",
    "cross_validation_visualization(lambdas, rmse_tr_cv, rmse_te_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.nanargmin(rmse_te_cv)\n",
    "lambda_ri = lambdas[idx]\n",
    "\n",
    "print(\"lambda* ={lambda_}\\n\\nrmse train={rmse_tr}\\n\\nrmse test={rmse_te}\".format(\n",
    "    lambda_=lambda_ri, rmse_tr=rmse_tr_cv[idx], rmse_te=rmse_te_cv[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bias-variance decomposition for complexity determination***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variance_decomposition_visualization(degrees, loss_tr, loss_te):\n",
    "    \"\"\"visualize the bias variance decomposition.\"\"\"\n",
    "    loss_tr_mean = np.expand_dims(np.mean(loss_tr, axis=0), axis=0)\n",
    "    loss_te_mean = np.expand_dims(np.mean(loss_te, axis=0), axis=0)\n",
    "    plt.plot(degrees, loss_tr.T, 'b', linestyle=\"-\", label='train', linewidth=0.3)\n",
    "    plt.plot(degrees, loss_te.T, 'r', linestyle=\"-\", label='test', linewidth=0.3)\n",
    "    plt.plot(degrees, loss_tr_mean.T, 'b', linestyle=\"-\", label='train', linewidth=3)\n",
    "    plt.plot(degrees, loss_te_mean.T, 'r', linestyle=\"-\", label='test', linewidth=3)\n",
    "    plt.xlabel(\"degree\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.ylim(0, 10)\n",
    "    plt.title(\"Bias-Variance Decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_train = 0.05\n",
    "seeds = range(50)\n",
    "degrees = range(0, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_tr_bv = np.empty((len(seeds), len(degrees)))\n",
    "rmse_te_bv = np.empty((len(seeds), len(degrees)))\n",
    "\n",
    "for index_seed, seed in enumerate(seeds):\n",
    "    np.random.seed(seed)\n",
    "    x_tr, x_te, y_tr, y_te = split_data(tX, y, ratio_train, seed)        \n",
    "    \n",
    "    for index_deg, deg in enumerate(degrees): \n",
    "        tx_tr = build_poly(x_tr, deg)\n",
    "        tx_te = build_poly(x_te, deg)\n",
    "            \n",
    "        w_tr, mse_tr = ridge_regression(y_tr, tx_tr, lambda_ri)\n",
    "        mse_te = compute_mse(y_te, tx_te, w_tr)\n",
    "            \n",
    "        rmse_tr_bv[index_seed][index_deg] = np.sqrt(2*mse_tr)\n",
    "        rmse_te_bv[index_seed][index_deg] = np.sqrt(2*mse_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_variance_decomposition_visualization(degrees, rmse_tr_bv, rmse_te_bv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot above, change the value of `degree_ri` manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_te_bv = np.array(rmse_te_bv)\n",
    "rmse_tr_bv = np.array(rmse_tr_bv)\n",
    "\n",
    "idx = np.nanargmin(np.abs(np.mean(rmse_te_bv-rmse_tr_bv, axis=0)))\n",
    "\n",
    "degree_ri = 6\n",
    "\n",
    "print(\"degree* ={degree}\\n\\nrmse train={rmse_tr}\\n\\nrmse test={rmse_te}\".format(\n",
    "    degree=degree_ri, rmse_tr=rmse_tr_bv[idx].mean(), rmse_te=rmse_te_bv[idx].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_poly = build_poly(tX, degree_ri)\n",
    "            \n",
    "w_ri, mse_ri = ridge_regression(y, tX_poly, lambda_ri)\n",
    "\n",
    "print(\"final w* shape ={w}\\n\\nfinal degree* ={degree}\\n\\nfinal lambda*={lambda_}\\n\\nmse={loss}\".format(w=w_ri.shape, \\\n",
    "            degree=degree_ri, lambda_=lambda_ri, loss = mse_ri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = np.where(y==-1, 0, y)\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 1000\n",
    "gammas = np.logspace(-10, -1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_lr = np.empty(len(gammas))\n",
    "ws_lr = np.empty((len(gammas), len(initial_w)))\n",
    "for idx, gamma in enumerate(gammas):\n",
    "    (w, loss) = logistic_regression(y, tX, initial_w, max_iters, gamma)\n",
    "    losses_lr[idx] = loss\n",
    "    ws_lr[idx, :] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the losses per gamma used\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(gammas, losses_lr)\n",
    "\n",
    "ax.set(xlabel='gamma', ylabel='loglikelihood',\n",
    "       title='Log likelihood per choice of learning rate')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.nanargmin(losses_lr)\n",
    "\n",
    "w_lr = ws_lr[idx]\n",
    "gamma_lr = gammas[idx]\n",
    "\n",
    "print(\"w* ={w}\\n\\nloglikelihood loss={loss}\\n\\ngamma={gamma}\".format(\n",
    "    w=w_lr, loss=losses_lr[idx], gamma = gamma_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularized logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 1000\n",
    "gammas = np.logspace(-10, -1, 20)\n",
    "lambda_rlr =lambda_ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_rlr = np.empty(len(gammas))\n",
    "ws_rlr = np.empty((len(gammas), len(initial_w)))\n",
    "for idx, gamma in enumerate(gammas):\n",
    "    (w, loss) = reg_logistic_regression(y, tX, lambda_rlr, initial_w, max_iters, gamma)\n",
    "    losses_rlr[idx] = loss\n",
    "    ws_rlr[idx, :] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the losses per gamma used\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(gammas, losses_rlr)\n",
    "\n",
    "ax.set(xlabel='gamma', ylabel='loglikelihood',\n",
    "       title='Log likelihood per choice of learning rate')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.nanargmin(losses_rlr)\n",
    "\n",
    "w_rlr = ws_rlr[idx]\n",
    "gamma_rlr = gammas[idx]\n",
    "\n",
    "print(\"w* ={w}\\n\\nloglikelihood loss={loss}\\n\\ngamma={gamma}\".format(\n",
    "    w=w_rlr, loss=losses_rlr[idx], gamma = gamma_rlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross-validation hyperparameter selection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "degree_rlr = 1\n",
    "k_fold = 4\n",
    "lambdas = np.logspace(-15, 1, 20)\n",
    "max_iters = 1000\n",
    "initial_w = np.zeros(tX.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "loss_tr_cv = np.empty(len(lambdas))\n",
    "loss_te_cv = np.empty(len(lambdas))\n",
    "\n",
    "for index_lambda, lambda_ in enumerate(lambdas):\n",
    "    log_tr = np.empty(k_fold)\n",
    "    log_te = np.empty(k_fold)\n",
    "    for k in range(k_fold):\n",
    "        loss_tr, loss_te = cross_validation_log(y, tX, k_indices, k, lambda_, degree_rlr, initial_w, max_iters, gamma_rlr)\n",
    "        log_tr[k] = np.sqrt(2*loss_tr)\n",
    "        log_te[k] = np.sqrt(2*loss_te)\n",
    "    loss_tr_cv[index_lambda] = np.mean(log_tr)\n",
    "    loss_te_cv[index_lambda] = np.mean(log_te)\n",
    "cross_validation_visualization(lambdas, loss_tr_cv, loss_te_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.nanargmin(loss_te_cv)\n",
    "lambda_rlr = lambdas[idx]\n",
    "\n",
    "print(\"lambda* ={lambda_}\\n\\nloglikelihood train={log_tr}\\n\\nloglikelihood test={log_te}\".format(\n",
    "    lambda_=lambda_rlr, log_tr=loss_tr_cv[idx], log_te=loss_te_cv[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bias-variance decomposition for complexity determination***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_train = 0.05\n",
    "seeds = range(50)\n",
    "degrees = range(0, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tr_bv = np.empty((len(seeds), len(degrees)))\n",
    "loss_te_bv = np.empty((len(seeds), len(degrees)))\n",
    "\n",
    "for index_seed, seed in enumerate(seeds):\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    x_tr, x_te, y_tr, y_te = split_data(tX, y, ratio_train, seed)        \n",
    "\n",
    "    for index_deg, deg in enumerate(degrees): \n",
    "        tx_tr = build_poly(x_tr, deg)\n",
    "        tx_te = build_poly(x_te, deg)\n",
    "        \n",
    "        initial_w = np.zeros(tx_tr.shape[1])\n",
    "        \n",
    "        w_tr, log_tr = reg_logistic_regression(y_tr, tx_tr, lambda_rlr, initial_w, max_iters, gamma_rlr)\n",
    "        log_te = compute_loglikelihood(y_te, tx_te, w_tr)\n",
    "            \n",
    "        loss_tr_bv[index_seed][index_deg] = log_tr\n",
    "        loss_tr_bv[index_seed][index_deg] = log_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_variance_decomposition_visualization(degrees, loss_tr_bv, loss_te_bv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot above, change the value of `degree_rlr` manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_te_bv = np.array(loss_te_bv)\n",
    "loss_tr_bv = np.array(loss_tr_bv)\n",
    "\n",
    "idx = np.nanargmin(np.mean(loss_te_bv-loss_tr_bv, axis=1))\n",
    "\n",
    "degree_ri = 6\n",
    "\n",
    "print(\"degree* ={degree}\\n\\nloglikelihood train={loss_tr}\\n\\nloglikelihood test={loss_te}\".format(\n",
    "    degree=degree_rlr, loss_tr=loss_tr_bv[idx].mean(), rmse_te=loss_te_bv[idx].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting vs Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods application and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the calculated variables to keep them without having to re-run everything\n",
    "# w_ls, w_gd, gamma_gd, w_sgd, gamma_sgd, w_ri, degree_ri, lambda_ri\n",
    "# w_lr, gamma_lr, w_rlr, gamma_rlr, lambda_rlr, degree_rlr\n",
    "ws = (w_ls, w_gd, w_sgd, w_ri, w_lr, w_rlr)\n",
    "degs = (degree_ri , degree_rlr)\n",
    "gammas = (gamma_gd, gamma_sgd, gamma_lr, gamma_rlr)\n",
    "lambdas = (lambda_ri, lambda_rlr)\n",
    "\n",
    "np.savetxt('weights.txt', ws, fmt='%s', delimiter=',', newline='\\n')\n",
    "np.savetxt('degrees.txt', degs, fmt='%s', delimiter=',', newline='\\n')\n",
    "np.savetxt('gammas.txt', gammas, fmt='%s', delimiter=',', newline='\\n')\n",
    "np.savetxt('lambdas.txt', lambdas, fmt='%s', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w_ri\n",
    "#weights = np.insert(weights, rmX, 0, axis = 0)\n",
    "\n",
    "tX_test = np.delete(tX_test, rmX, axis=1)\n",
    "# keep only columns that do not have too much missing data\n",
    "tX, rmX = train_data_formatting(tX_test, degree = 10, cutoff = 1.0, \n",
    "                      imputation = impute_median, interaction = False)\n",
    "tX_test = np.apply_along_axis(standardize, 1, tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/sample-submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
