{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "import os\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'train.csv'\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "y, tX, ids = load_csv_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change later : Simple data description \n",
    "- all variables are floating point, except PRI_jet_num which is integer\n",
    "- variables prefixed with PRI (for PRImitives) are “raw” quantities about the bunch collision as measured by the detector.\n",
    "- variables prefixed with DER (for DERived) are quantities computed from the primitive features, which were selected by the physicists of ATLAS.\n",
    "- it can happen that for some entries some variables are meaningless or cannot be computed; in this case, their value is −999.0, which is outside the normal range of all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape = (250000,)\n",
      "tX shape =(250000, 30)\n",
      "ids shape = (250000,)\n"
     ]
    }
   ],
   "source": [
    "print('y shape = ' + str(y.shape) + '\\ntX shape =' + str(tX.shape) + '\\nids shape = ' + str(ids.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire : Dataprocessing: \n",
    "- Truc qui évalue les NA\n",
    "- Fonction qui vire ou non un featues basé sur un seul\n",
    "- Remplace les NA par la moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first transform the categorical variable (PRI_jet_num) into four dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_factor(x, nlevels=4, column_idx = 22):\n",
    "    new_var = np.zeros((x.shape[0], nlevels))\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(nlevels):\n",
    "            if x[i,column_idx] == j:\n",
    "                new_var[j,0] = 1\n",
    "                \n",
    "    x = np.delete(x, column_idx, axis = 1)\n",
    "    \n",
    "    return x, new_var\n",
    "\n",
    "def missingness_filter(cX, cutoff = 0.5):\n",
    "    \n",
    "    cX = np.where(cX == -999, np.nan, cX)\n",
    "    missingness = np.sum(np.isnan(cX), axis = 0)/cX.shape[0]\n",
    "    \n",
    "    to_remove = np.where(missingness > cutoff)[0]\n",
    "    \n",
    "    return np.delete(cX, to_remove, axis = 1), to_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 29) (250000, 4)\n",
      "(250000, 22)\n"
     ]
    }
   ],
   "source": [
    "cX, fac_X = separate_factor(tX)\n",
    "print(cX.shape, fac_X.shape)\n",
    "\n",
    "filt_cX = missingness_filter(cX, 0.6)\n",
    "print(filt_cX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\" Lolynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    poly = np.ones((len(x), 1))\n",
    "    for deg in range(1, degree+1):\n",
    "        poly = np.c_[poly, np.power(x, deg)]\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "print(arr, arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_poly(arr,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lin_combination(x):\n",
    "    \n",
    "    comb = np.ones((x.shape[0],)).reshape(-1,1)\n",
    "    \n",
    "    for i in range(x.shape[1]-1):\n",
    "        \n",
    "        for j in range(i+1,x.shape[1]):\n",
    "            \n",
    "            temp = x[:,i] * x[:,j]\n",
    "            \n",
    "            comb = np.concatenate((comb, temp.reshape(-1,1)), axis=1)\n",
    "            \n",
    "    return np.delete(comb, 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_comb = build_lin_combination(cX)\n",
    "print(lin_comb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1,2,np.nan,4], [5,np.nan,7,8], [np.nan,10,11,np.nan]])\n",
    "print(arr, arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mean(x):\n",
    "    out = np.zeros(x.shape)\n",
    "    for i in range(x.shape[1]):\n",
    "        temp = x[:,i]\n",
    "        mean = np.nanmean(temp)\n",
    "        out[:,i] = np.nan_to_num(temp, nan = mean)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def impute_median(x):\n",
    "    out = np.zeros(x.shape)\n",
    "    for i in range(x.shape[1]):\n",
    "        temp = x[:,i]\n",
    "        median = np.nanmedian(temp)\n",
    "        out[:,i] = np.nan_to_num(temp, nan = median)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def impute_gaussian(x):\n",
    "    out = np.zeros(x.shape)\n",
    "    for i in range(x.shape[1]):\n",
    "        temp = x[:,i]\n",
    "        mean = np.nanmean(temp)\n",
    "        std = np.nanstd(temp)\n",
    "        \n",
    "        for j in range(x.shape[0]):\n",
    "            out[j,i] = np.nan_to_num(temp[j], nan = np.random.normal(loc=mean, scale=std))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_formatting(tX, degree = 2, cutoff = 0.6, imputation = impute_mean, lin_comb = False):\n",
    "    \n",
    "    #separating out the categorical variables\n",
    "    cont_X, fac_X = separate_factor(tX)\n",
    "    \n",
    "    #applying a missingness filter on the columns/features\n",
    "    cont_X, to_remove = missingness_filter(cont_X, cutoff)\n",
    "    \n",
    "    #imputing the missing data\n",
    "    cont_X = imputation(cont_X)\n",
    "    \n",
    "    poly = build_poly(cont_X, degree)\n",
    "    \n",
    "    poly = np.concatenate((poly, fac_X), axis=1)\n",
    "    \n",
    "    if lin_comb:\n",
    "        lin = build_lin_combination(cont_X)\n",
    "        \n",
    "        return np.concatenate((poly, lin), axis=1), to_remove\n",
    "    \n",
    "    return poly, to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting the meaningless values to the median of the column\n",
    "tX = np.where(tX==-999., np.nan,tX)\n",
    "med_X = np.nanmedian(tX, axis=0)\n",
    "\n",
    "inds = np.where(np.isnan(tX))\n",
    "tX[inds] = np.take(med_X, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(tX[0] == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove categorical data and standarize the rest\n",
    "ntX = np.delete(tX, 22, axis=1)\n",
    "ntX = np.apply_along_axis(standardize, 1, ntX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
